# Skill: Release AA Backend to Production
# Promotes automation-analytics-backend from stage to production via app-interface

name: release_aa_backend_prod
description: |
  Release Automation Analytics backend to production.
  This skill guides you through the promotion process from stage to production
  by updating the commit SHA in app-interface and creating a PR for approval.

  Resolves paths and Quay images from config.json.
version: "1.2"

links:
  depends_on:
    - appinterface_check    # Verify app-interface config before release
    - scan_vulnerabilities   # Scan image before production
  validates:
    - release_to_prod       # AA-specific release validates generic release process
    - appinterface_check    # Successful release validates app-interface config
  validated_by:
    - environment_overview  # Production health check validates release
    - appinterface_check
  chains_to:
    - close_issue           # Close related issues
    - notify_team           # Announce release
    - environment_overview  # Verify production health
    - check_integration_tests  # Verify integration tests pass post-release
  provides_context_for:
    - weekly_summary        # Release in weekly report
    - beer                  # EOD release activity

inputs:
  - name: commit_sha
    type: string
    required: true
    description: "Full SHA1 commit to release (must exist in automation-analytics-backend repo and have image in Quay)"

  - name: release_date
    type: string
    required: false
    default: "{{ today }}"
    description: "Release date for Jira title (YYYY-MM-DD format, defaults to today)"

  - name: include_billing
    type: boolean
    required: false
    default: false
    description: "Also promote the billing component to production"

# No hardcoded constants - resolved dynamically from config.json

steps:
  # ==================== LOAD RELEASE PERSONA ====================
  # Start with release persona for git, quay, and appinterface tools
  # Will switch to developer for jira/gitlab tools as needed

  - name: load_release_persona
    description: "Load release persona for Git, Quay, and app-interface tools"
    tool: persona_load
    args:
      persona_name: "release"

  - name: init_autoheal
    description: "Initialize failure tracking"
    compute: |
      result = {"release_failures": []}
    output: autoheal_state
    on_error: continue

  # ==================== KNOWLEDGE INTEGRATION ====================

  - name: check_release_known_issues
    description: "Check for known release/deployment issues"
    compute: |
      # Check known issues for release operations
      release_issues = memory.check_known_issues("release", "") or {}
      quay_issues = memory.check_known_issues("quay", "") or {}
      appinterface_issues = memory.check_known_issues("app-interface", "") or {}
      deploy_issues = memory.check_known_issues("deploy", "") or {}

      all_issues = []
      for issues in [release_issues, quay_issues, appinterface_issues, deploy_issues]:
          if issues and issues.get("matches"):
              all_issues.extend(issues.get("matches", [])[:2])

      result = {
          "has_known_issues": len(all_issues) > 0,
          "issues": all_issues[:5],
      }
    output: release_known_issues
    on_error: continue

  - name: get_release_gotchas
    description: "Get release-related gotchas from knowledge"
    tool: knowledge_query
    args:
      project: "automation-analytics-backend"
      persona: "release"
      section: "gotchas"
    output: release_gotchas_raw
    on_error: continue

  - name: parse_release_gotchas
    description: "Parse release-related gotchas"
    compute: |
      gotchas_result = release_gotchas_raw if 'release_gotchas_raw' in dir() and release_gotchas_raw else {}

      release_gotchas = []
      if isinstance(gotchas_result, dict) and gotchas_result.get('found'):
          content = gotchas_result.get('content', [])
          if isinstance(content, list):
              # Filter for release-related gotchas
              for g in content:
                  g_str = str(g).lower()
                  if any(kw in g_str for kw in ['release', 'prod', 'deploy', 'sha', 'quay', 'app-interface', 'promote']):
                      release_gotchas.append(g)

      result = {
          'gotchas': release_gotchas[:5],
          'has_gotchas': len(release_gotchas) > 0,
      }
    output: prod_release_gotchas
    on_error: continue

  # ==================== LOAD CONFIG ====================

  - name: load_config
    description: "Load release configuration from config.json"
    compute: |
      import os
      from scripts.common.config_loader import load_config

      config = load_config()
      repos = config.get("repositories", {})
      ai_config = config.get("app_interface", {})
      quay_config = config.get("quay", {})
      ns_config = config.get("namespaces", {}).get("production", {})
      paths_cfg = config.get("paths", {})

      # Get repo paths
      backend_cfg = repos.get("automation-analytics-backend", {})
      ai_cfg = repos.get("app-interface", {})

      # Use workspace_roots as fallback
      workspace_roots = paths_cfg.get("workspace_roots", [])
      default_backend = ""
      default_ai = ""
      for root in workspace_roots:
          if os.path.exists(os.path.join(os.path.expanduser(root), "automation-analytics-backend")):
              default_backend = os.path.join(os.path.expanduser(root), "automation-analytics-backend")
          if os.path.exists(os.path.join(os.path.expanduser(root), "app-interface")):
              default_ai = os.path.join(os.path.expanduser(root), "app-interface")

      result = {
          "backend_repo": backend_cfg.get("path", default_backend),
          "appinterface_repo": ai_cfg.get("path") or ai_config.get("path", default_ai),
          "deploy_file": ai_config.get("deploy_file", "data/services/insights/tower-analytics/cicd/deploy-clowder.yml"),
          "quay_image": f"quay.io/redhat-services-prod/{quay_config.get('repositories', {}).get('automation-analytics', 'aap-aa-tenant/aap-aa-main/automation-analytics-backend-main')}",
          "quay_repository": quay_config.get("repositories", {}).get("automation-analytics", "aap-aa-tenant/aap-aa-main/automation-analytics-backend-main"),
          "namespace_main": ns_config.get("main", "tower-analytics-prod"),
          "namespace_billing": ns_config.get("billing", "tower-analytics-prod-billing"),
          "prod_namespace_pattern": "tower-analytics-prod.yml",
          "billing_namespace_pattern": "tower-analytics-prod-billing.yml",
      }
    output: cfg
  # ==================== VERIFICATION ====================

  # Step 1: Verify commit exists in backend repo
  - name: verify_commit_exists
    description: "Verify the commit SHA exists in automation-analytics-backend"
    tool: git_log
    args:
      repo: "{{ cfg.backend_repo }}"
      limit: 1
    output: commit_info

  - name: validate_commit_exists
    description: "Validate that the commit SHA exists in the repo"
    compute: |
      import subprocess
      backend_repo = cfg['backend_repo']
      commit_sha = inputs.commit_sha
      try:
          proc = subprocess.run(
              ["git", "cat-file", "-t", commit_sha],
              cwd=backend_repo,
              capture_output=True, text=True, timeout=30,
          )
          if proc.returncode != 0:
              raise Exception(
                  f"Commit {commit_sha} not found in automation-analytics-backend. "
                  "Did you fetch latest?"
              )
          result = f"Validation passed: commit {commit_sha[:12]} exists (type: {proc.stdout.strip()})"
      except FileNotFoundError:
          raise Exception(
              f"Backend repo not found at {backend_repo}. Check config paths."
          )

  # Step 2: Verify image exists in Quay
  - name: verify_quay_image
    description: "Verify the container image exists in Quay.io"
    tool: quay_get_tag
    args:
      repository: "aap-aa-tenant/aap-aa-main/automation-analytics-backend-main"
      tag: "{{ inputs.commit_sha }}"
      namespace: "redhat-services-prod"
    output: quay_image
    on_error: auto_heal  # Quay API - may need auth

  - name: validate_quay_image
    description: "Validate the Quay image was found"
    compute: |
      image_result = str(quay_image) if 'quay_image' in dir() and quay_image else ""
      if not image_result or "not found" in image_result.lower() or "error" in image_result.lower():
          raise Exception(
              f"Image not found in Quay for SHA {inputs.commit_sha}. "
              "Build may not have completed."
          )
      result = f"Validation passed: Quay image exists for {inputs.commit_sha[:12]}"

  # ==================== GET CURRENT STATE ====================

  # Step 3: Get current production SHA from deploy file
  - name: get_current_prod_sha
    description: "Read current production SHA from app-interface using shared parser"
    compute: |
      from scripts.common.parsers import parse_deploy_clowder_ref

      deploy_path = f"{cfg['appinterface_repo']}/{cfg['deploy_file']}"
      with open(deploy_path, 'r') as f:
        content = f.read()

      # Use shared parser to extract ref
      current_sha = parse_deploy_clowder_ref(content, "tower-analytics-prod")

      if not current_sha:
        raise Exception("Could not find production ref in deploy-clowder.yml")

      result = current_sha
    output: current_prod_sha

  # Step 4: Get commit log for changelog (using compute with subprocess since git_log doesn't support range)
  - name: get_changelog_log
    description: "Get list of commits being released"
    compute: |
      import subprocess
      backend_repo = cfg['backend_repo']
      try:
          cmd = ["git", "log", "--oneline", f"{current_prod_sha}..{inputs.commit_sha}"]
          proc = subprocess.run(cmd, cwd=backend_repo, capture_output=True, text=True, timeout=30)
          result = proc.stdout.strip() if proc.returncode == 0 else "No commits found"
      except Exception as e:
          result = f"Error getting changelog: {e}"
    output: changelog_raw
    on_error: continue

  - name: format_changelog
    description: "Format changelog output"
    compute: |
      commits_str = str(changelog_raw) if changelog_raw else ""

      if not commits_str.strip() or "error" in commits_str.lower():
        result = "No new commits (same SHA as current production)"
      else:
        # Split into lines and format as markdown list
        lines = [line.strip() for line in commits_str.strip().split('\n') if line.strip()]
        commit_count = len(lines)
        # Format each commit as a bullet point with code formatting for the SHA
        formatted_lines = []
        for line in lines:
            # Each line is like "df42bb8b Merge branch..."
            parts = line.split(' ', 1)
            if len(parts) == 2:
                sha, msg = parts
                formatted_lines.append(f"- `{sha}` {msg}")
            else:
                formatted_lines.append(f"- {line}")
        result = f"üì¶ **{commit_count} commits** to release:\n\n" + "\n".join(formatted_lines)
    output: changelog

  # ==================== CREATE JIRA ISSUE ====================
  # Switch to developer persona for Jira tools

  - name: load_developer_persona_for_jira
    description: "Load developer persona for Jira tools"
    tool: persona_load
    args:
      persona_name: "developer"

  # Step 5: Create release Jira issue (uses jira_create_issue tool directly)
  - name: create_jira_issue_raw
    description: "Create Jira story for tracking this release"
    tool: jira_create_issue
    args:
      summary: "{{ inputs.release_date }} Analytics HCC Service Release"
      issue_type: "Story"
      project: "AAP"
      description: "Production release tracking for {{ inputs.release_date }}\n\nCommit SHA: {{ inputs.commit_sha }}"
      labels: "release,production"
    output: jira_issue_raw
    on_error: continue

  - name: parse_jira_issue
    description: "Parse Jira issue key from tool output"
    compute: |
      import re
      # Parse issue key from output like "‚úÖ Issue created: AAP-64709\n..."
      issue_key = None
      issue_url = None
      if jira_issue_raw:
          match = re.search(r'(AAP-\d+)', str(jira_issue_raw))
          if match:
              issue_key = match.group(1)
              issue_url = f"https://issues.redhat.com/browse/{issue_key}"
      result = {"key": issue_key, "url": issue_url, "raw": str(jira_issue_raw) if jira_issue_raw else None}
    output: jira_issue
    on_error: continue

  # ==================== PREPARE APP-INTERFACE ====================
  # Switch back to release persona for git and app-interface tools

  - name: load_release_persona_for_appinterface
    description: "Load release persona for Git and app-interface tools"
    tool: persona_load
    args:
      persona_name: "release"

  # Step 6: Ensure app-interface is clean and up to date
  - name: check_appinterface_status
    description: "Check app-interface repo status"
    tool: git_status
    args:
      repo: "{{ cfg.appinterface_repo }}"
    output: appinterface_status

  - name: validate_clean_repo
    description: "Ensure no uncommitted changes"
    compute: |
      status = str(appinterface_status) if 'appinterface_status' in dir() and appinterface_status else ""
      if status and "working tree clean" not in status.lower():
          # Check for signs of uncommitted changes
          if any(indicator in status.lower() for indicator in ["modified", "changes not staged", "changes to be committed", "untracked"]):
              raise Exception(
                  "app-interface has uncommitted changes. Please commit or stash them first."
              )
      result = "Validation passed: repository is clean"

  # Step 7: Checkout master and pull latest
  - name: checkout_master
    description: "Switch to master branch"
    tool: git_checkout
    args:
      repo: "{{ cfg.appinterface_repo }}"
      target: "master"

  - name: fetch_upstream
    description: "Fetch latest from upstream"
    tool: git_fetch
    args:
      repo: "{{ cfg.appinterface_repo }}"
      remote: "upstream"
    on_error: auto_heal  # Git remote - may need auth/network

  - name: rebase_upstream
    description: "Rebase on upstream master"
    tool: git_rebase
    args:
      repo: "{{ cfg.appinterface_repo }}"
      onto: "upstream/master"
    output: pull_result
    on_error: continue

  # Step 8: Get existing branches (using compute with subprocess since git_branch_list doesn't support pattern)
  - name: list_existing_branches
    description: "Check for existing release branches"
    compute: |
      import subprocess
      import re

      appinterface_repo = cfg['appinterface_repo']
      release_date = inputs.release_date
      if not re.match(r'^\d{4}-\d{2}-\d{2}$', release_date):
          result = ""
      else:
          try:
              proc = subprocess.run(
                  ["git", "branch", "-a"],
                  cwd=appinterface_repo, capture_output=True, text=True, timeout=30
              )
              pattern = f"aa-release-{release_date}"
              result = "\n".join(line.strip() for line in proc.stdout.splitlines() if pattern in line)
          except Exception as e:
              result = ""
    output: existing_branches_raw
    on_error: continue

  - name: create_branch_name
    description: "Determine branch name (handle existing versions)"
    compute: |
      from scripts.common.parsers import parse_git_branches, get_next_version

      release_date = inputs.release_date
      base_name = f"aa-release-{release_date}"

      # Parse existing branches
      existing = parse_git_branches(str(existing_branches_raw) if existing_branches_raw else "")
      matching = [b for b in existing if base_name in b]

      if not matching:
          branch_name = base_name
          version = 1
      else:
          # Use shared function to get next version
          version = get_next_version(matching, base_name)
          branch_name = f"{base_name}-v{version}"

      result = {"name": branch_name, "version": version, "existing": len(matching), "release_date": release_date}
    output: branch_info

  - name: create_release_branch
    description: "Create branch for this release"
    tool: git_checkout
    args:
      repo: "{{ cfg.appinterface_repo }}"
      target: "{{ branch_info.name }}"
      force_create: true
    output: branch_result

  - name: set_branch_name
    compute: |
      result = branch_info["name"]
    output: branch_name

  # ==================== UPDATE DEPLOY FILE ====================

  # Step 9: Update production ref in deploy-clowder.yml
  - name: update_prod_ref
    description: "Update production namespace ref to new SHA using shared parser"
    compute: |
      from scripts.common.parsers import update_deploy_clowder_ref

      appinterface_repo = cfg['appinterface_repo']
      deploy_file = cfg['deploy_file']
      deploy_path = f"{appinterface_repo}/{deploy_file}"

      with open(deploy_path, 'r') as f:
        content = f.read()

      # Use shared function to update ref
      new_content, success = update_deploy_clowder_ref(content, inputs.commit_sha, "tower-analytics-prod")

      if not success:
        raise Exception("Could not find production ref pattern in deploy-clowder.yml")

      with open(deploy_path, 'w') as f:
        f.write(new_content)

      result = f"Updated tower-analytics-prod ref: {current_prod_sha[:12]} ‚Üí {inputs.commit_sha[:12]}"
    output: prod_update_result

  # Step 10: Optionally update billing ref
  - name: update_billing_ref
    description: "Update billing production namespace ref (if requested) using shared parser"
    condition: "{{ inputs.include_billing }}"
    compute: |
      from scripts.common.parsers import update_deploy_clowder_ref

      appinterface_repo = cfg['appinterface_repo']
      deploy_file = cfg['deploy_file']
      deploy_path = f"{appinterface_repo}/{deploy_file}"

      with open(deploy_path, 'r') as f:
        content = f.read()

      # Use shared function to update billing ref
      new_content, success = update_deploy_clowder_ref(content, inputs.commit_sha, "tower-analytics-prod-billing")

      if not success:
        raise Exception("Could not find billing production ref pattern")

      with open(deploy_path, 'w') as f:
        f.write(new_content)

      result = f"Updated tower-analytics-prod-billing ref to {inputs.commit_sha[:12]}"
    output: billing_update_result

  # ==================== COMMIT AND PUSH ====================

  # Step 11: Stage and commit changes
  - name: stage_changes
    description: "Stage the deploy file changes"
    tool: git_add
    args:
      repo: "{{ cfg.appinterface_repo }}"
      files: "{{ cfg.deploy_file }}"

  - name: build_commit_message
    description: "Build commit message following commit lint rules"
    compute: |
      # Commit format: {issue_key} - {type}({scope}): {description}
      # jira_issue is now a dict with 'key', 'url', 'raw'
      issue_key = jira_issue.get('key', '') if jira_issue else ''

      description = f"release {inputs.commit_sha[:12]} to production"
      if inputs.include_billing:
        description += " (including billing)"

      # The git_commit tool will format this properly with issue_key and commit_type
      result = {
        "description": description,
        "issue_key": issue_key or '',
      }
    output: commit_message

  - name: commit_changes
    description: "Commit the release changes following commit lint rules"
    tool: git_commit
    args:
      repo: "{{ cfg.appinterface_repo }}"
      message: "{{ commit_message.description }}"
      issue_key: "{{ commit_message.issue_key }}"
      commit_type: "chore"
      scope: "release"

  # Step 12: Push branch to origin
  - name: push_branch
    description: "Push release branch to origin"
    tool: git_push
    args:
      repo: "{{ cfg.appinterface_repo }}"
      branch: "{{ branch_name }}"
      set_upstream: true
    output: push_result

  # Step 13: Build MR title following release format
  - name: build_mr_title
    description: "Build MR title in format: AAP-XXXXX - YYYY-MM-DD Analytics HCC Service Release"
    compute: |
      issue_key = jira_issue.get('key', '') if jira_issue else ''
      release_date = inputs.release_date

      if issue_key:
        title = f"{issue_key} - {release_date} Analytics HCC Service Release"
      else:
        title = f"{release_date} Analytics HCC Service Release"

      result = title
    output: mr_title

  # Switch to developer persona for GitLab tools
  - name: load_developer_persona_for_gitlab
    description: "Load developer persona for GitLab tools"
    tool: persona_load
    args:
      persona_name: "developer"

  # Step 14: Build MR description with proper formatting
  - name: build_mr_description
    description: "Build MR description with properly formatted changelog"
    compute: |
      # Build the MR description with explicit newlines
      jira_key = jira_issue.get('key', 'N/A') if jira_issue else 'N/A'
      quay_image = cfg.get('quay_image', 'quay.io/redhat-services-prod/aap-aa-tenant/aap-aa-main/automation-analytics-backend-main')

      billing_line = "- [x] tower-analytics-prod-billing\n" if inputs.include_billing else ""

      lines = [
          f"## Release: {inputs.release_date} Analytics HCC Service",
          "",
          f"**Commit SHA:** `{inputs.commit_sha}`",
          f"**Jira:** {jira_key}",
          "",
          "### Changes Included",
          "",
          changelog,
          "",
          "### Components Updated",
          "- [x] tower-analytics-prod (main)",
          billing_line,
          "### Quay Image",
          f"`{quay_image}:{inputs.commit_sha}`",
          "",
          "### Checklist",
          "- [ ] Verified image exists in Quay",
          "- [ ] Reviewed changelog",
          "- [ ] Stage has been validated",
          "- [ ] Ready for production deployment",
      ]
      result = "\n".join(lines)
    output: mr_description

  # Step 15: Create merge request
  - name: create_mr
    description: "Create merge request for team approval"
    tool: gitlab_mr_create
    args:
      project: "app-interface"
      title: "{{ mr_title }}"
      description: "{{ mr_description }}"
      target_branch: "master"
      source_branch: "{{ branch_name }}"
      draft: false
    output: mr_result
    on_error: auto_heal  # GitLab API - may need auth refresh

  # ==================== UPDATE JIRA ====================

  # Step 14: Add MR link to Jira issue
  - name: update_jira_with_mr
    description: "Add MR link to Jira issue"
    condition: "{{ jira_issue }}"
    tool: jira_add_comment
    args:
      issue_key: "{{ jira_issue.key }}"
      comment: |
        App-Interface MR created: {{ mr_result.web_url }}

        Releasing commit: {{ inputs.commit_sha }}
        {{ changelog }}
    on_error: auto_heal  # Jira API - may need auth refresh

  # Step 15: Emit release started hook
  - name: emit_release_started_hook
    description: "Notify team channel about release"
    condition: "mr_result"
    compute: |
      # emit_event is available from skill engine safe_globals
      if emit_event:
          # Emit release started
          emit_event("release_started", {
              "sha": inputs.commit_sha[:12],
              "environment": "production",
          })

          # Also emit release MR ready
          emit_event("release_mr_ready", {
              "mr_url": mr_result.get('web_url', ''),
              "sha": inputs.commit_sha[:12],
          })
          result = "hooks sent"
      else:
          result = "hooks skipped: emit_event not available"
    output: release_hook_result
    on_error: continue

  # Step 16: Notify team via Slack (skill chain)
  - name: notify_team_release_ready
    description: "Notify team channel about production release MR"
    condition: "mr_result and mr_result.get('web_url')"
    tool: skill_run
    args:
      skill_name: notify_team
      inputs: |
        {
          "message": "",
          "template": "release",
          "template_data": {
            "version": "{{ inputs.release_date }}",
            "environments": ["production"],
            "release_url": "{{ mr_result.get('web_url', '') }}",
            "changelog": "SHA: {{ inputs.commit_sha[:12] }}\nJira: {{ jira_issue.get('key', 'N/A') if jira_issue else 'N/A' }}"
          }
        }
      execute: true
    output: slack_release_notification
    on_error: continue

  # ==================== MEMORY INTEGRATION ====================

  - name: log_release
    description: "Log release to session and track deployment"
    compute: |
      # Use shared memory helpers
      memory.append_to_list(
          "state/environments",
          "recent_deployments",
          {
              "version": inputs.release_date,
              "sha": inputs.commit_sha[:12],
              "environment": "production",
              "deployed_at": memory.get_timestamp(),
              "mr_url": mr_result.get("web_url", "") if mr_result else "",
              "jira_key": jira_issue.get("key", "") if jira_issue else "",
          }
      )
      # Trim to last 10 deployments
      data = memory.read_memory("state/environments")
      if len(data.get("recent_deployments", [])) > 10:
          data["recent_deployments"] = data["recent_deployments"][:10]
          memory.write_memory("state/environments", data)
      result = "deployment tracked"
    output: memory_update_result
    on_error: continue

  - name: session_log_release
    description: "Log release to session"
    tool: memory_session_log
    args:
      action: "Prepared production release {{ inputs.release_date }}"
      details: "SHA: {{ inputs.commit_sha[:12] }}, Jira: {{ jira_issue.key if jira_issue else 'N/A' }}"
    on_error: continue

  - name: track_production_releases
    description: "Track production releases for patterns"
    compute: |
      from datetime import datetime

      # Load patterns
      patterns = memory.read_memory("learned/patterns") or {}
      if "production_releases" not in patterns:
          patterns["production_releases"] = []

      # Record this release
      release_record = {
          "release_date": inputs.release_date,
          "commit_sha": inputs.commit_sha[:40],
          "previous_sha": current_prod_sha[:40] if current_prod_sha else None,
          "include_billing": inputs.include_billing,
          "jira_key": jira_issue.key if jira_issue else None,
          "mr_created": bool(mr_result) if 'mr_result' in dir() else False,
          "timestamp": datetime.now().isoformat(),
      }

      patterns["production_releases"].append(release_record)

      # Keep last 100 releases
      patterns["production_releases"] = patterns["production_releases"][-100:]

      memory.write_memory("learned/patterns", patterns)
      result = "release tracked"
    output: release_tracking_result
    on_error: continue

  - name: update_release_state
    description: "Update release state in memory"
    compute: |
      from datetime import datetime

      # Update release state
      state_data = memory.read_memory("state/releases") or {}
      if "production" not in state_data:
          state_data["production"] = {}

      state_data["production"]["last_release"] = {
          "date": inputs.release_date,
          "sha": inputs.commit_sha[:12],
          "previous_sha": current_prod_sha[:12] if current_prod_sha else None,
          "jira_key": jira_issue.key if jira_issue else None,
          "mr_url": mr_result.get("web_url", "") if mr_result else None,
          "timestamp": datetime.now().isoformat(),
      }

      # Track release frequency
      if "release_count" not in state_data["production"]:
          state_data["production"]["release_count"] = 0
      state_data["production"]["release_count"] += 1

      memory.write_memory("state/releases", state_data)
      result = "release state updated"
    output: release_state_result
    on_error: continue

  # ==================== LEARNING FROM FAILURES ====================

  - name: detect_release_failures
    description: "Detect failure patterns from release operations"
    compute: |
      errors_detected = []

      # Check Quay failures
      quay_text = str(quay_image) if 'quay_image' in dir() and quay_image else ""
      if "not found" in quay_text.lower() or "manifest unknown" in quay_text.lower():
          errors_detected.append({
              "tool": "quay_check_image_exists",
              "pattern": "image not found",
              "cause": "Image not built yet - Konflux build may not have completed",
              "fix": "Wait for Konflux build to complete, check with konflux_list_builds()"
          })

      # Check GitLab MR failures
      mr_text = str(mr_result) if 'mr_result' in dir() and mr_result else ""
      if "no such host" in mr_text.lower():
          errors_detected.append({
              "tool": "gitlab_mr_create",
              "pattern": "no such host",
              "cause": "VPN not connected - internal GitLab not reachable",
              "fix": "Run vpn_connect() to connect to Red Hat VPN"
          })

      # Check Jira failures
      jira_text = str(jira_issue) if 'jira_issue' in dir() and jira_issue else ""
      if "unauthorized" in jira_text.lower():
          errors_detected.append({
              "tool": "jira_create_issue",
              "pattern": "unauthorized",
              "cause": "Jira authentication failed or token expired",
              "fix": "Check Jira credentials in config.json"
          })

      result = errors_detected
    output: release_errors_detected
    on_error: continue

  - name: learn_release_image_failure
    description: "Learn from image not found failures"
    condition: "release_errors_detected and any(e.get('pattern') == 'image not found' for e in release_errors_detected)"
    tool: learn_tool_fix
    args:
      tool_name: "quay_check_image_exists"
      error_pattern: "image not found"
      root_cause: "Image not built yet - Konflux build may not have completed"
      fix_description: "Wait for Konflux build to complete, check with konflux_list_builds()"
    output: release_image_fix_learned
    on_error: continue

  - name: learn_release_vpn_failure
    description: "Learn from GitLab VPN failures"
    condition: "release_errors_detected and any(e.get('pattern') == 'no such host' for e in release_errors_detected)"
    tool: learn_tool_fix
    args:
      tool_name: "gitlab_mr_create"
      error_pattern: "no such host"
      root_cause: "VPN not connected - internal GitLab not reachable"
      fix_description: "Run vpn_connect() to connect to Red Hat VPN"
    output: release_vpn_fix_learned
    on_error: continue

# ==================== OUTPUT ====================

outputs:
  - name: summary
    value: |
      ## ‚úÖ Production Release Prepared

      **Release Date:** {{ inputs.release_date }}
      **Commit SHA:** `{{ inputs.commit_sha }}`

      ### Jira Issue
      {{ jira_issue.key if jira_issue else '‚ö†Ô∏è Jira issue not created' }}

      ### Merge Request
      {{ mr_result.web_url if mr_result else '‚ö†Ô∏è MR not created' }}

      ### Changes Included
      {{ changelog }}

      ### Components
      - ‚úÖ tower-analytics-prod (main)
      {% if inputs.include_billing %}- ‚úÖ tower-analytics-prod-billing{% else %}- ‚è≠Ô∏è tower-analytics-prod-billing (skipped){% endif %}

      ---

      ### Next Steps
      1. üëÄ Review the MR: {{ mr_result.web_url if mr_result else 'N/A' }}
      2. ‚úÖ Get team approval
      3. üöÄ Merge to trigger deployment
      4. üìä Monitor deployment in ArgoCD/App-Interface
      5. ‚úÖ Verify pods are healthy in `tower-analytics-prod`

      ### Monitoring Commands
      ```
      kubectl_get_pods(namespace='tower-analytics-prod', environment='production')
      prometheus_query(query='up{namespace="tower-analytics-prod"}', environment='production')
      ```

      ### Rollback (if needed)
      If issues arise, create a new release with the previous SHA:
      ```
      skill_run("release_aa_backend_prod", '{"commit_sha": "{{ current_prod_sha }}"}')
      ```

      {% if prod_release_gotchas and prod_release_gotchas.has_gotchas %}
      ---

      ### ‚ö†Ô∏è Release Gotchas

      {% for gotcha in prod_release_gotchas.gotchas[:3] %}
      - {{ gotcha }}
      {% endfor %}
      {% endif %}

      {% if release_known_issues and release_known_issues.has_known_issues %}
      ---

      ### üí° Known Issues

      {% for issue in release_known_issues.issues[:3] %}
      - {{ issue.pattern if issue.pattern else issue }}
      {% endfor %}
      {% endif %}

  - name: context
    value:
      jira_key: "{{ jira_issue.key if jira_issue else none }}"
      mr_url: "{{ mr_result.web_url if mr_result else none }}"
      branch: "{{ branch_name }}"
      old_sha: "{{ current_prod_sha }}"
      new_sha: "{{ inputs.commit_sha }}"
      include_billing: "{{ inputs.include_billing }}"
