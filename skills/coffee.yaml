# Skill: Morning Coffee Briefing
# Your daily standup assistant - everything you need to start the day

name: coffee
description: |
  Morning briefing - everything you need to know at the start of your work day.
  
  This skill gathers and summarizes:
  - ğŸ“… Calendar: Today's meetings with Meet links
  - ğŸ“§ Email: Unread emails categorized (people vs newsletters)
  - ğŸ”€ PRs: Your open PRs, feedback waiting, failed pipelines
  - ğŸ‘€ Reviews: PRs assigned to you for review
  - ğŸ“‹ Jira: Sprint activity for last day/week
  - ğŸš€ Merges: Recent merged code in aa-backend
  - ğŸ§ª Ephemeral: Your active test environments with expiry
  - ğŸ“ Yesterday: Your commits (for standup prep)
  - ğŸš¨ Alerts: Any firing or recent alerts
  - ğŸ¯ Actions: Suggested next steps
  
  Requires: Gmail API access (same OAuth as Calendar)
version: "1.1"

inputs:
  - name: full_email_scan
    type: boolean
    required: false
    default: false
    description: "Process all unread emails (vs just summary)"
  
  - name: auto_archive_email
    type: boolean
    required: false
    default: false
    description: "Automatically archive processed emails"
  
  - name: days_back
    type: integer
    required: false
    default: 1
    description: "Days to look back for activity (default: 1)"

steps:
  # ==================== CONFIGURATION ====================
  
  - name: load_config
    description: "Load configuration"
    compute: |
      import json
      from pathlib import Path
      from datetime import datetime
      from zoneinfo import ZoneInfo
      
      config_paths = [
        Path.cwd() / "config.json",
        Path.home() / "src/redhat-ai-workflow/config.json",
      ]
      config = {}
      for p in config_paths:
        if p.exists():
          with open(p) as f:
            config = json.load(f)
          break
      
      tz = ZoneInfo("Europe/Dublin")
      now = datetime.now(tz)
      
      result = {
        "config": config,
        "now": now.isoformat(),
        "today": now.strftime("%Y-%m-%d"),
        "day_name": now.strftime("%A"),
        "time": now.strftime("%H:%M"),
        "greeting": "Good morning" if now.hour < 12 else "Good afternoon" if now.hour < 18 else "Good evening",
      }
    output: ctx

  # ==================== CALENDAR ====================
  
  - name: get_todays_calendar
    description: "Fetch today's calendar events"
    compute: |
      from pathlib import Path
      from datetime import datetime, timedelta
      from zoneinfo import ZoneInfo
      
      CONFIG_DIR = Path.home() / ".config" / "google-calendar"
      TOKEN_FILE = CONFIG_DIR / "token.json"
      TIMEZONE = "Europe/Dublin"
      tz = ZoneInfo(TIMEZONE)
      
      events_today = []
      
      if TOKEN_FILE.exists():
        try:
          from google.oauth2.credentials import Credentials
          from googleapiclient.discovery import build
          
          SCOPES = [
            "https://www.googleapis.com/auth/calendar.readonly",
          ]
          
          creds = Credentials.from_authorized_user_file(str(TOKEN_FILE), SCOPES)
          service = build('calendar', 'v3', credentials=creds)
          
          now = datetime.now(tz)
          day_start = now.replace(hour=0, minute=0, second=0, microsecond=0)
          day_end = day_start + timedelta(days=1)
          
          events_result = service.events().list(
            calendarId='primary',
            timeMin=day_start.isoformat(),
            timeMax=day_end.isoformat(),
            singleEvents=True,
            orderBy='startTime',
            timeZone=TIMEZONE,
          ).execute()
          
          for event in events_result.get('items', []):
            start = event['start'].get('dateTime', event['start'].get('date'))
            try:
              if 'T' in start:
                dt = datetime.fromisoformat(start.replace('Z', '+00:00')).astimezone(tz)
                time_str = dt.strftime('%H:%M')
              else:
                time_str = "All day"
            except:
              time_str = start
            
            # Check for Meet link
            meet_link = ""
            if event.get('conferenceData', {}).get('entryPoints'):
              for entry in event['conferenceData']['entryPoints']:
                if entry.get('entryPointType') == 'video':
                  meet_link = entry.get('uri', '')
                  break
            
            events_today.append({
              "time": time_str,
              "title": event.get('summary', 'No title'),
              "meet_link": meet_link,
            })
        except Exception as e:
          events_today = [{"error": str(e)}]
      else:
        events_today = [{"error": "Calendar not configured"}]
      
      result = events_today
    output: calendar_events

  # ==================== EMAIL (Gmail) ====================
  
  - name: get_email_summary
    description: "Fetch and summarize unread emails"
    compute: |
      from pathlib import Path
      
      CONFIG_DIR = Path.home() / ".config" / "google-calendar"
      TOKEN_FILE = CONFIG_DIR / "token.json"
      
      email_summary = {
        "unread_count": 0,
        "important": [],
        "newsletters": 0,
        "notifications": 0,
        "error": None,
      }
      
      if TOKEN_FILE.exists():
        try:
          from google.oauth2.credentials import Credentials
          from googleapiclient.discovery import build
          
          # Gmail scopes - need to be added to OAuth
          SCOPES = [
            "https://www.googleapis.com/auth/gmail.readonly",
            "https://www.googleapis.com/auth/gmail.modify",
          ]
          
          creds = Credentials.from_authorized_user_file(str(TOKEN_FILE), SCOPES)
          service = build('gmail', 'v1', credentials=creds)
          
          # Get unread messages
          results = service.users().messages().list(
            userId='me',
            q='is:unread',
            maxResults=50
          ).execute()
          
          messages = results.get('messages', [])
          email_summary["unread_count"] = len(messages)
          
          # Categorize messages
          for msg in messages[:20]:  # Process first 20
            msg_data = service.users().messages().get(
              userId='me',
              id=msg['id'],
              format='metadata',
              metadataHeaders=['Subject', 'From']
            ).execute()
            
            headers = {h['name']: h['value'] for h in msg_data.get('payload', {}).get('headers', [])}
            subject = headers.get('Subject', 'No subject')
            sender = headers.get('From', 'Unknown')
            
            # Categorize
            sender_lower = sender.lower()
            subject_lower = subject.lower()
            
            if 'newsletter' in sender_lower or 'digest' in subject_lower:
              email_summary["newsletters"] += 1
            elif 'notification' in sender_lower or 'noreply' in sender_lower:
              email_summary["notifications"] += 1
            else:
              # Important - from people
              email_summary["important"].append({
                "subject": subject[:60],
                "from": sender.split('<')[0].strip()[:30],
              })
          
        except Exception as e:
          error_str = str(e)
          if "gmail" in error_str.lower() or "scope" in error_str.lower():
            email_summary["error"] = "Gmail API not enabled. Run /setup-gmail to configure."
          else:
            email_summary["error"] = error_str
      else:
        email_summary["error"] = "Google OAuth not configured"
      
      result = email_summary
    output: email_summary
    on_error: continue

  # ==================== OPEN PRs (using MCP tools) ====================
  
  - name: get_open_prs
    description: "Get all open PRs in the repo"
    tool: gitlab_mr_list
    args:
      project: "automation-analytics/automation-analytics-backend"
    output: all_open_prs_raw
    on_error: continue

  - name: get_my_prs
    description: "Get PRs authored by me"
    tool: gitlab_mr_list
    args:
      project: "automation-analytics/automation-analytics-backend"
      author: "@me"
    output: my_prs_raw
    on_error: continue

  - name: parse_my_prs
    description: "Parse MR list output"
    compute: |
      import re
      
      my_mrs = []
      if my_prs_raw:
        for line in str(my_prs_raw).split('\n'):
          match = re.search(r'!(\d+)\s+\S+\s+(.+?)\s*\(main\)', line)
          if match:
            my_mrs.append({
              "id": int(match.group(1)),
              "title": match.group(2).strip()[:60]
            })
      
      result = my_mrs
    output: my_prs

  - name: check_pr_feedback
    description: "Check my PRs for new feedback (reuses check_mr_feedback pattern)"
    compute: |
      import subprocess
      import re
      
      feedback = []
      
      # Bot patterns to filter (same as check_mr_feedback skill)
      bot_patterns = [
        r'group_\d+_bot', r'konflux', r'Starting Pipelinerun',
        r'stone-prod', r'tkn pr logs', r'Integration test for component',
        r'aap-aa-on-pull-request', r'^/retest', r'^/approve',
      ]
      
      for pr in my_prs[:5]:  # Check last 5
        mr_id = pr['id']
        
        result = subprocess.run(
          ["glab", "mr", "view", str(mr_id), "--comments", "-R", "automation-analytics/automation-analytics-backend"],
          capture_output=True,
          text=True
        )
        
        # Find human comments (same logic as check_mr_feedback)
        for line in result.stdout.split('\n'):
          if ' commented ' in line and 'daoneill' not in line.lower():
            is_bot = any(re.search(p, line, re.IGNORECASE) for p in bot_patterns)
            if not is_bot:
              match = re.match(r'^(\w+) commented', line)
              if match:
                feedback.append({
                  "mr_id": mr_id,
                  "author": match.group(1),
                  "title": pr['title'][:40]
                })
                break  # One per MR
      
      result = feedback
    output: pr_feedback
    on_error: continue

  # ==================== JIRA ACTIVITY (using MCP tool) ====================
  
  - name: get_sprint_activity
    description: "Get Jira activity for the sprint"
    tool: jira_search
    args:
      jql: "project = AAP AND updated >= -{{ inputs.days_back or 1 }}d AND component = 'Automation Analytics' ORDER BY updated DESC"
      max_results: 20
    output: jira_activity_raw
    on_error: continue

  - name: parse_jira_activity
    description: "Parse Jira search results"
    compute: |
      import re
      
      recent_issues = []
      if jira_activity_raw:
        for line in str(jira_activity_raw).split('\n'):
          # Parse: AAP-12345  Summary text or AAP-12345: Summary text
          match = re.match(r'(AAP-\d+)[:\s]+(.+)', line)
          if match:
            recent_issues.append({
              "key": match.group(1),
              "summary": match.group(2)[:50]
            })
      
      result = {
        "count": len(recent_issues),
        "issues": recent_issues[:10]
      }
    output: jira_activity
    on_error: continue

  # ==================== MERGED CODE (using MCP tool) ====================
  
  - name: get_recent_merges
    description: "Get recently merged MRs"
    tool: gitlab_mr_list
    args:
      project: "automation-analytics/automation-analytics-backend"
      state: "merged"
    output: recent_merges_raw
    on_error: continue

  - name: parse_recent_merges
    description: "Parse merged MRs"
    compute: |
      import re
      
      merged_mrs = []
      if recent_merges_raw:
        for line in str(recent_merges_raw).split('\n')[:10]:
          match = re.search(r'!(\d+)\s+\S+\s+(.+?)\s*\(main\)', line)
          if match:
            merged_mrs.append({
              "id": int(match.group(1)),
              "title": match.group(2).strip()[:50]
            })
      
      result = merged_mrs[:5]  # Last 5
    output: recent_merges
    on_error: continue

  # ==================== ALERTS ====================
  
  - name: check_alerts
    description: "Check for any firing alerts"
    compute: |
      # This would use Prometheus/Alertmanager tools if available
      # For now, check Slack alert channels
      alerts = {
        "stage": [],
        "production": [],
        "error": None
      }
      
      # Could integrate with alertmanager_get_alerts tool
      # For now, return placeholder
      result = alerts
    output: alerts
    on_error: continue

  # ==================== FAILED PIPELINES ====================
  
  - name: check_failed_pipelines
    description: "Check for failed pipelines on your MRs"
    compute: |
      import subprocess
      import re
      
      failed_pipelines = []
      
      # Get your open MRs and check their pipeline status
      for pr in my_prs[:5] if my_prs else []:
        mr_id = pr.get('id')
        if not mr_id:
          continue
        
        # Get MR details including pipeline status
        result = subprocess.run(
          ["glab", "mr", "view", str(mr_id), "-R", "automation-analytics/automation-analytics-backend"],
          capture_output=True,
          text=True
        )
        
        output = result.stdout.lower()
        if 'failed' in output or 'canceled' in output:
          failed_pipelines.append({
            "mr_id": mr_id,
            "title": pr.get('title', '')[:40],
            "status": "failed" if 'failed' in output else "canceled"
          })
      
      result = failed_pipelines
    output: failed_pipelines
    on_error: continue

  # ==================== EPHEMERAL NAMESPACES (using MCP tool) ====================
  
  - name: check_ephemeral_namespaces
    description: "List your active ephemeral environments"
    tool: bonfire_namespace_list
    args:
      mine: true
    output: ephemeral_namespaces_raw
    on_error: continue

  - name: parse_ephemeral_namespaces
    description: "Parse namespace list"
    compute: |
      import re
      
      namespaces = []
      if ephemeral_namespaces_raw:
        for line in str(ephemeral_namespaces_raw).split('\n'):
          # Parse: ephemeral-xxxxx  expires in 2h 30m
          match = re.search(r'(ephemeral-\w+)\s+.*?(\d+[hm].*?)(?:\s|$)', line)
          if match:
            namespaces.append({
              "name": match.group(1),
              "expires": match.group(2).strip()
            })
          elif 'ephemeral-' in line:
            # Fallback: just get the namespace name
            ns_match = re.search(r'(ephemeral-\w+)', line)
            if ns_match:
              namespaces.append({
                "name": ns_match.group(1),
                "expires": "unknown"
              })
      
      result = namespaces
    output: ephemeral_namespaces
    on_error: continue

  # ==================== YESTERDAY'S WORK ====================
  
  - name: get_yesterdays_commits
    description: "Get your commits from yesterday (for standup)"
    compute: |
      import subprocess
      import re
      import os
      from datetime import datetime, timedelta
      
      commits = []
      
      # Get commits from yesterday
      yesterday = (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')
      
      result = subprocess.run(
        ["git", "log", "--oneline", "--author=daoneill", f"--since={yesterday}", "--until=today"],
        capture_output=True,
        text=True,
        cwd=os.path.expanduser("~/src/automation-analytics-backend")
      )
      
      for line in result.stdout.strip().split('\n')[:10]:
        if line.strip():
          # Parse: abc1234 Commit message
          parts = line.split(' ', 1)
          if len(parts) == 2:
            commits.append({
              "sha": parts[0][:7],
              "message": parts[1][:60]
            })
      
      result = commits
    output: yesterdays_commits
    on_error: continue

  # ==================== REVIEW REQUESTS (using MCP tool) ====================
  
  - name: get_review_requests
    description: "Get PRs where you're assigned as reviewer"
    tool: gitlab_mr_list
    args:
      project: "automation-analytics/automation-analytics-backend"
      reviewer: "@me"
    output: review_requests_raw
    on_error: continue

  - name: parse_review_requests
    description: "Parse review request list"
    compute: |
      import re
      
      review_requests = []
      if review_requests_raw:
        for line in str(review_requests_raw).split('\n'):
          match = re.search(r'!(\d+)\s+\S+\s+(.+?)\s*\(main\)', line)
          if match:
            review_requests.append({
              "id": int(match.group(1)),
              "title": match.group(2).strip()[:50]
            })
      
      result = review_requests[:5]  # Limit to 5
    output: review_requests
    on_error: continue

  # ==================== SUMMARY ====================
  
  - name: format_briefing
    description: "Create the morning briefing"
    compute: |
      import re
      
      lines = []
      
      # Header
      lines.append(f"# â˜• {ctx['greeting']}, Dave!")
      lines.append(f"")
      lines.append(f"**{ctx['day_name']}, {ctx['today']}** | {ctx['time']} Irish time")
      lines.append("")
      lines.append("---")
      lines.append("")
      
      # Calendar
      lines.append("## ğŸ“… Today's Calendar")
      if calendar_events and not any('error' in e for e in calendar_events):
        if calendar_events:
          for event in calendar_events:
            meet_icon = "ğŸ“¹" if event.get('meet_link') else ""
            lines.append(f"- **{event['time']}** - {event['title']} {meet_icon}")
        else:
          lines.append("- No meetings scheduled! ğŸ‰")
      else:
        lines.append("- âš ï¸ Calendar not accessible")
      lines.append("")
      
      # Email
      lines.append("## ğŸ“§ Email Summary")
      if email_summary and not email_summary.get('error'):
        lines.append(f"- **{email_summary['unread_count']}** unread emails")
        if email_summary['important']:
          lines.append(f"- **{len(email_summary['important'])}** from people:")
          for email in email_summary['important'][:5]:
            lines.append(f"  - {email['from']}: *{email['subject']}*")
        if email_summary['newsletters']:
          lines.append(f"- {email_summary['newsletters']} newsletters")
        if email_summary['notifications']:
          lines.append(f"- {email_summary['notifications']} notifications")
      else:
        error = email_summary.get('error', 'Unknown') if email_summary else 'Not configured'
        lines.append(f"- âš ï¸ {error}")
      lines.append("")
      
      # PRs needing attention
      lines.append("## ğŸ”€ PR Status")
      lines.append(f"")
      lines.append(f"**Your Open PRs:** {len(my_prs) if my_prs else 0}")
      if my_prs:
        for pr in my_prs[:5]:
          lines.append(f"- !{pr['id']} - {pr['title']}")
      lines.append("")
      
      if pr_feedback:
        lines.append(f"**âš ï¸ Feedback Waiting ({len(pr_feedback)}):**")
        for fb in pr_feedback:
          lines.append(f"- !{fb['mr_id']} - Comment from **{fb['author']}**")
      else:
        lines.append("âœ… No pending feedback on your PRs")
      lines.append("")
      
      # Failed pipelines
      if failed_pipelines:
        lines.append(f"**ğŸ”´ Failed Pipelines ({len(failed_pipelines)}):**")
        for fp in failed_pipelines:
          lines.append(f"- !{fp['mr_id']} - {fp['status'].upper()}")
        lines.append("")
      
      # Review requests
      if review_requests:
        lines.append(f"**ğŸ‘€ Awaiting Your Review ({len(review_requests)}):**")
        for rr in review_requests:
          lines.append(f"- !{rr['id']} - {rr['title']}")
        lines.append("")
      
      # Open PRs to review
      lines.append(f"**Open PRs to Review:** {all_open_prs.count('!') if all_open_prs else 0} total")
      lines.append("")
      
      # Jira
      lines.append("## ğŸ“‹ Jira Activity")
      if jira_activity:
        lines.append(f"**{jira_activity.get('count', 0)}** issues updated in last {inputs.get('days_back', 1)} day(s)")
        for issue in jira_activity.get('issues', [])[:5]:
          lines.append(f"- {issue['key']}: {issue['summary']}")
      else:
        lines.append("- Could not fetch Jira activity")
      lines.append("")
      
      # Merges
      lines.append("## ğŸš€ Recent Merges")
      if recent_merges:
        for mr in recent_merges:
          lines.append(f"- !{mr['id']} - {mr['title']}")
      else:
        lines.append("- No recent merges")
      lines.append("")
      
      # Ephemeral Environments
      lines.append("## ğŸ§ª Ephemeral Environments")
      if ephemeral_namespaces:
        for ns in ephemeral_namespaces:
          expires = ns.get('expires', 'unknown')
          lines.append(f"- **{ns['name']}** - expires {expires}")
      else:
        lines.append("- No active ephemeral environments")
      lines.append("")
      
      # Yesterday's Work (for standup)
      lines.append("## ğŸ“ Yesterday's Work")
      if yesterdays_commits:
        for commit in yesterdays_commits[:5]:
          lines.append(f"- `{commit['sha']}` {commit['message']}")
      else:
        lines.append("- No commits yesterday")
      lines.append("")
      
      # Alerts
      lines.append("## ğŸš¨ Alerts")
      if alerts and not alerts.get('error'):
        if alerts.get('production') or alerts.get('stage'):
          for env, alert_list in alerts.items():
            if alert_list and env != 'error':
              lines.append(f"**{env.upper()}:**")
              for a in alert_list:
                lines.append(f"- {a}")
        else:
          lines.append("âœ… No active alerts")
      else:
        lines.append("- Alert check not configured")
      lines.append("")
      
      # Actions
      lines.append("---")
      lines.append("")
      lines.append("## ğŸ¯ Suggested Actions")
      actions = []
      
      if pr_feedback:
        actions.append(f"- Respond to feedback on {len(pr_feedback)} PR(s)")
      if failed_pipelines:
        actions.append(f"- Fix {len(failed_pipelines)} failed pipeline(s)")
      if review_requests:
        actions.append(f"- Review {len(review_requests)} PR(s) assigned to you")
      if email_summary and email_summary.get('important'):
        actions.append(f"- Review {len(email_summary['important'])} important emails")
      if ephemeral_namespaces:
        expiring = [ns for ns in ephemeral_namespaces if 'h' in str(ns.get('expires', '')) and int(re.search(r'(\d+)h', str(ns.get('expires', '0h'))).group(1) if re.search(r'(\d+)h', str(ns.get('expires', ''))) else 99) < 2]
        if expiring:
          actions.append(f"- â° {len(expiring)} ephemeral env(s) expiring soon!")
      
      if actions:
        for a in actions:
          lines.append(a)
      else:
        lines.append("- You're all caught up! â˜•")
      
      result = '\n'.join(lines)
    output: briefing

outputs:
  - name: summary
    value: "{{ briefing }}"
  
  - name: context
    value:
      calendar_count: "{{ calendar_events | length if calendar_events else 0 }}"
      unread_emails: "{{ email_summary.unread_count if email_summary else 0 }}"
      my_prs: "{{ my_prs | length if my_prs else 0 }}"
      feedback_waiting: "{{ pr_feedback | length if pr_feedback else 0 }}"
      failed_pipelines: "{{ failed_pipelines | length if failed_pipelines else 0 }}"
      review_requests: "{{ review_requests | length if review_requests else 0 }}"
      ephemeral_envs: "{{ ephemeral_namespaces | length if ephemeral_namespaces else 0 }}"
      yesterdays_commits: "{{ yesterdays_commits | length if yesterdays_commits else 0 }}"
      jira_updates: "{{ jira_activity.count if jira_activity else 0 }}"
      recent_merges: "{{ recent_merges | length if recent_merges else 0 }}"

