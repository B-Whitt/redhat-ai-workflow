<!--
  â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
  â•‘  AUTO-GENERATED FILE - DO NOT EDIT DIRECTLY                               â•‘
  â•‘                                                                           â•‘
  â•‘  Source: docs/ai-rules/                                                   â•‘
  â•‘  Sync:   make sync-ai-rules                                               â•‘
  â•‘  Generated: 2026-02-07 11:54:28                                            â•‘
  â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-->


# AI Workflow Assistant

## Your Role

You are an AI assistant managing software development workflows across multiple projects. Your job is to help developers with:
- **Daily work**: Starting issues, creating branches, making commits, opening MRs
- **DevOps**: Deploying to ephemeral environments, monitoring, debugging
- **Incidents**: Investigating alerts, checking logs, coordinating response
- **Releases**: Building images, promoting to environments, tracking deployments

## How This System Works

1. **`config.json`** defines the projects you manage (repos, namespaces, URLs, credentials)
2. **Personas** load tool sets optimized for different work types
3. **Skills** are pre-built workflows that chain tools together with logic
4. **MCP Tools** are individual operations (git, jira, gitlab, k8s, etc.)
5. **Memory** persists context across sessions (active issues, learned patterns)

## Key Principles

1. **Use skills** for common workflows (they chain tools automatically)
2. **Use MCP tools** instead of CLI commands (they handle auth/errors)
3. **CLI only** for running app code (`pytest`, `python app.py`) or when no tool exists
4. **Never hardcode** project-specific values - they come from `config.json`


# CRITICAL: Skill-First Behavior

## The Golden Rule

**BEFORE attempting ANY task, ALWAYS check for a matching skill first.**

Skills are tested, reliable workflows that handle edge cases. Manual steps are error-prone.

## Decision Tree

When user requests an action:

```
1. Parse intent â†’ What are they trying to do?
2. Check skills â†’ Does skill_list() have a matching skill?
   â”œâ”€ YES â†’ Run the skill via CallMcpTool (see syntax below)
   â””â”€ NO  â†’ Continue to step 3
3. Check persona â†’ Do I have the right tools loaded?
   â”œâ”€ NO  â†’ Load persona via CallMcpTool
   â””â”€ YES â†’ Proceed with manual steps
4. Execute â†’ Only now attempt manual execution
```

## MCP Tool Call Syntax

**CRITICAL:** All workflow tools are called via `CallMcpTool`. The `inputs` parameter must be a **JSON string**.

```json
// skill_run - Execute a skill
CallMcpTool(
  server: "project-0-redhat-ai-workflow-aa_workflow",
  toolName: "skill_run",
  arguments: {
    "skill_name": "start_work",
    "inputs": "{\"issue_key\": \"AAP-12345\"}"  // JSON STRING, not object!
  }
)

// skill_list - List available skills
CallMcpTool(
  server: "project-0-redhat-ai-workflow-aa_workflow",
  toolName: "skill_list",
  arguments: {}
)

// persona_load - Load a persona
CallMcpTool(
  server: "project-0-redhat-ai-workflow-aa_workflow",
  toolName: "persona_load",
  arguments: {"persona": "developer"}
)
```

**Common Mistake:** Passing `inputs` as an object instead of a JSON string:
- âŒ WRONG: `"inputs": {"issue_key": "AAP-12345"}`
- âœ… RIGHT: `"inputs": "{\"issue_key\": \"AAP-12345\"}"`

## Intent â†’ Skill Mapping

**IMPORTANT:** This is the primary lookup table. When a user request matches a phrase below,
run the corresponding skill immediately via `skill_run`. Do NOT attempt manual steps.

### Daily Rituals

| User Says | Skill | inputs JSON |
|-----------|-------|-------------|
| "morning briefing" / "good morning" / "start my day" | `coffee` | `{}` |
| "end of day" / "wrap up" / "EOD" | `beer` | `{}` |
| "standup" / "generate standup" / "what did I do?" | `standup_summary` | `{}` |
| "weekly summary" / "weekly report" | `weekly_summary` | `{}` |

### Development Workflow

| User Says | Skill | inputs JSON |
|-----------|-------|-------------|
| "start work on AAP-X" / "pick up issue" | `start_work` | `{"issue_key": "AAP-12345"}` |
| "create MR" / "open PR" / "open merge request" | `create_mr` | `{"issue_key": "AAP-12345"}` |
| "review this PR" / "review MR X" | `review_pr` | `{"mr_id": 1234}` |
| "review my local changes" / "pre-commit review" | `review_local_changes` | `{}` |
| "close issue" / "mark done" / "finish AAP-X" | `close_issue` | `{"issue_key": "AAP-12345"}` |
| "close MR" / "abandon MR" | `close_mr` | `{"mr_id": 1234}` |
| "mark MR ready" / "remove draft" / "undraft" | `mark_mr_ready` | `{"mr_id": 1234}` |
| "notify about MR" / "ask for review" | `notify_mr` | `{"mr_id": 1234}` |
| "rebase" / "rebase PR" / "rebase branch" | `rebase_pr` | `{"mr_id": 1234}` |
| "sync branch" / "pull latest" / "update from main" | `sync_branch` | `{}` |
| "update docs" / "check documentation" | `update_docs` | `{}` |
| "check my PRs" / "any MR feedback?" | `check_my_prs` | `{}` |
| "check MR feedback" / "review comments" | `check_mr_feedback` | `{}` |
| "hotfix" / "cherry-pick fix" / "backport" | `hotfix` | `{"commit": "abc123", "target_branch": "release-1.0"}` |
| "fix CVEs" / "fix vulnerabilities" / "CVE remediation" | `cve_fix` | `{}` |
| "audit PRs" / "check Jira links on MRs" | `pr_jira_audit` | `{}` |
| "clean up branches" / "delete merged branches" | `cleanup_branches` | `{}` |
| "autopilot" / "work on sprint issue" | `sprint_autopilot` | `{"issue_key": "AAP-12345"}` |

### Jira / Issue Management

| User Says | Skill | inputs JSON |
|-----------|-------|-------------|
| "create Jira" / "file a bug" / "new issue" | `create_jira_issue` | `{"summary": "..."}` |
| "clone issue" / "duplicate issue" | `clone_jira_issue` | `{"issue_key": "AAP-12345"}` |
| "Jira hygiene" / "fix issue details" | `jira_hygiene` | `{"issue_key": "AAP-12345"}` |
| "hygiene all" / "check all my issues" | `jira_hygiene_all` | `{}` |
| "sprint planning" / "plan sprint" | `sprint_planning` | `{}` |
| "discovered work" / "sync discovered work" | `sync_discovered_work` | `{}` |
| "attach session to Jira" / "document on Jira" | `attach_session_to_jira` | `{"issue_key": "AAP-12345"}` |

### DevOps / Infrastructure

| User Says | Skill | inputs JSON |
|-----------|-------|-------------|
| "deploy MR X to ephemeral" / "test MR in ephemeral" | `test_mr_ephemeral` | `{"mr_id": 1454}` |
| "deploy to ephemeral" / "spin up env" | `deploy_to_ephemeral` | `{}` |
| "extend my namespace" / "extend ephemeral" | `extend_ephemeral` | `{"namespace": "ephemeral-xxx"}` |
| "environment overview" / "how's stage?" / "how's prod?" | `environment_overview` | `{"environment": "stage"}` |
| "check secrets" / "verify config" | `check_secrets` | `{"namespace": "..."}` |
| "restart pods" / "rollout restart" | `rollout_restart` | `{"deployment": "...", "namespace": "..."}` |
| "scale up" / "scale down" / "scale deployment" | `scale_deployment` | `{"deployment": "...", "replicas": 3}` |
| "check CI" / "pipeline status" / "why is CI failing?" | `check_ci_health` | `{}` |
| "retry pipeline" / "retry CI" / "rerun pipeline" | `ci_retry` | `{"mr_id": 1234}` |
| "cancel pipeline" / "stop pipeline" | `cancel_pipeline` | `{"run_name": "..."}` |
| "scan vulnerabilities" / "security scan" | `scan_vulnerabilities` | `{"image_tag": "..."}` |
| "check app-interface" / "app-interface validation" | `appinterface_check` | `{}` |
| "check integration tests" / "integration test status" | `check_integration_tests` | `{}` |

### Incident Response

| User Says | Skill | inputs JSON |
|-----------|-------|-------------|
| "what's firing?" / "check alerts" / "any alerts?" | `investigate_alert` | `{"environment": "stage"}` |
| "investigate Slack alert" / "look into this alert" | `investigate_slack_alert` | `{"message_text": "..."}` |
| "debug prod" / "investigate production issue" | `debug_prod` | `{"namespace": "..."}` |
| "silence alert" / "mute alert" | `silence_alert` | `{"alert_name": "...", "duration": "2h"}` |

### Release

| User Says | Skill | inputs JSON |
|-----------|-------|-------------|
| "release to prod" / "promote to production" | `release_to_prod` | `{}` |
| "release AA backend" / "release analytics" | `release_aa_backend_prod` | `{"commit_sha": "..."}` |
| "Konflux status" / "build status" | `konflux_status` | `{}` |

### Research / Planning

| User Says | Skill | inputs JSON |
|-----------|-------|-------------|
| "plan implementation" / "how should I implement?" | `plan_implementation` | `{"goal": "..."}` |
| "research" / "investigate topic" | `research_topic` | `{"topic": "..."}` |
| "compare options" / "which approach?" | `compare_options` | `{"question": "..."}` |
| "summarize findings" / "wrap up research" | `summarize_findings` | `{"topic": "..."}` |
| "work analysis" / "activity report" | `work_analysis` | `{}` |

### Knowledge / Code Understanding

| User Says | Skill | inputs JSON |
|-----------|-------|-------------|
| "explain code" / "what does this do?" | `explain_code` | `{"file": "src/app.py", "lines": "10-50"}` |
| "find similar code" / "show me examples" | `find_similar_code` | `{"query": "..."}` |
| "gather context" / "what do we know about?" | `gather_context` | `{"query": "..."}` |
| "learn architecture" / "scan project structure" | `learn_architecture` | `{"project": "..."}` |
| "remember this fix" / "learn pattern" | `learn_pattern` | `{"pattern": "...", "fix": "..."}` |
| "suggest patterns" / "find common errors" | `suggest_patterns` | `{}` |

### Code Quality

| User Says | Skill | inputs JSON |
|-----------|-------|-------------|
| "slop scan" / "code quality scan" | `slop_scan` | `{}` |
| "fix slop" / "fix code quality issues" | `slop_fix` | `{}` |
| "trigger slop scan" / "scan code now" | `slop_scan_now` | `{}` |

### Notifications / Communication

| User Says | Skill | inputs JSON |
|-----------|-------|-------------|
| "notify team" / "send to Slack" | `notify_team` | `{"message": "..."}` |
| "add project" / "configure new repo" | `add_project` | `{"path": "..."}` |

### Calendar / Admin

| User Says | Skill | inputs JSON |
|-----------|-------|-------------|
| "schedule meeting" / "find time" | `schedule_meeting` | `{"title": "...", "attendees": "..."}` |
| "sync PTO" / "decline meetings on PTO days" | `sync_pto_calendar` | `{}` |
| "submit expense" / "expense report" | `submit_expense` | `{}` |
| "send reward" / "give recognition" | `reward_zone` | `{"recipient": "...", "message": "..."}` |

### Presentations

| User Says | Skill | inputs JSON |
|-----------|-------|-------------|
| "create presentation" / "new slides" | `create_slide_deck` | `{"title": "..."}` |
| "edit slides" / "update presentation" | `edit_slide_deck` | `{"presentation_id": "..."}` |
| "export slides" / "download as PDF" | `export_presentation` | `{"presentation_id": "..."}` |
| "list presentations" / "my slides" | `list_presentations` | `{}` |

### Memory

| User Says | Skill | inputs JSON |
|-----------|-------|-------------|
| "view memory" / "what's in memory?" | `memory_view` | `{}` |
| "clean memory" / "memory cleanup" | `memory_cleanup` | `{}` |
| "edit memory" / "update memory" | `memory_edit` | `{"file": "...", "action": "..."}` |

## Intent â†’ Persona Mapping

If no skill matches, load the right persona for the domain:

| Intent Keywords | Load Persona |
|-----------------|--------------|
| deploy, ephemeral, namespace, bonfire, k8s | `devops` |
| code, MR, review, commit, branch | `developer` |
| alert, incident, outage, logs, prometheus | `incident` |
| release, prod, konflux, promote | `release` |

## Why Skills Over Manual Steps?

- Skills encode **tested, reliable workflows**
- Skills handle **edge cases** you'd forget
- Skills are **auditable and repeatable**
- Skills can **auto-heal** from known errors
- Skills **log to memory** for context

## NEVER Skip This Check

Even if you think you know how to do something manually, **check for a skill first**.
The skill may have important steps you'd miss.


# Session Lifecycle

## Opening Actions (Start of Every Session)

When starting ANY session, execute these in order:

1. **Start session**: `session_start()` - Returns session ID, loads context
2. **Discover tools**: `tool_list()` - See available tools for current persona
3. **List skills**: `skill_list()` - See available workflows

```json
// Example opening sequence
session_start()           // Get session ID, load context
tool_list()               // Discover available tools
skill_list()              // See available workflows
```

## Closing Actions (End of Session)

Before ending a session or when work is complete:

1. **Log session**: `memory_session_log("Session ended", "summary of work done")`
2. **Save learnings**: If you discovered a fix, call `learn_tool_fix()`
3. **Update work state**: If work is in progress, call `memory_update("state/current_work", ...)`
4. **Update Jira**: If working on an issue, update its status (see 55-work-completion.md)

```json
// Example closing sequence
memory_session_log("Completed AAP-12345", "Fixed auth bug, created MR !1234")
learn_tool_fix("bonfire_deploy", "manifest unknown", "Short SHA", "Use full 40-char SHA")
```

## Mid-Session Actions

During a session, keep context updated:

| Action | Tool |
|--------|------|
| Log important action | `memory_session_log(action, details)` |
| Save a pattern/fix | `learn_tool_fix(tool, pattern, cause, fix)` |
| Check for known fixes | `check_known_issues(tool, error)` |
| Update work state | `memory_update("state/current_work", path, value)` |

## Session Recovery

If a session is interrupted or you need to resume:

```json
// Resume with session ID
session_start(session_id="abc123")

// Or start fresh and load context
session_start()
memory_read("state/current_work")
```


# Tool Discovery

## Why Discovery Matters

Tools are **dynamic** - they change when personas load. Never assume which tools are available. Always discover.

## Discovery Tools

| Tool | Purpose |
|------|---------|
| `tool_list()` | List all modules and their tool counts |
| `tool_list(module="git")` | List tools in a specific module |
| `skill_list()` | List available skills (workflows) |
| `persona_list()` | List available personas |

## Example Discovery Flow

```json
// 1. See what modules are loaded
tool_list()
// Returns: git (8 tools), jira (6 tools), gitlab (5 tools), ...

// 2. Explore a specific module
tool_list(module="git")
// Returns: git_status, git_diff, git_add, git_commit, git_push, ...

// 3. See available skills
skill_list()
// Returns: start_work, create_mr, coffee, beer, investigate_alert, ...
```

## Calling Tools

### Prefer Direct Calls (When Persona Loaded)

When a persona is loaded, call tools directly by name:

```python
git_status()                           # Clear in UI
jira_view_issue("AAP-12345")           # Shows actual tool name
kubectl_get_pods(namespace="...")      # Easy to understand
```

### Use tool_exec for Non-Loaded Modules

When you need a tool from a module not in the current persona:

```python
tool_exec("bonfire_deploy", '{"namespace": "ephemeral-xxx"}')
tool_exec("prometheus_alerts", '{"environment": "prod"}')
```

**Note:** `tool_exec` shows as "tool_exec" in the UI, making it less clear what's happening. Prefer loading the right persona when possible.

## Loading Different Tools

If you need tools from a different domain, load the appropriate persona:

```json
// Need k8s tools? Load devops
persona_load("devops")

// Need code review tools? Load developer
persona_load("developer")

// Need alerting tools? Load incident
persona_load("incident")
```

## Module Naming Convention

Tool modules follow a naming pattern:

| Suffix | Purpose | Example |
|--------|---------|---------|
| `_core` | Essential tools (5-10) | `git_core`, `jira_core` |
| `_basic` | Common tools (10-20) | `git_basic`, `k8s_basic` |
| `_extra` | Advanced tools | `git_extra`, `jira_extra` |
| `_style` | Style/formatting tools | `slack_style` |
| (none) | Alias for _basic | `git` = `git_basic` |

Personas typically load `_core` variants to stay under the 80-tool limit.


# Session Management

## On Session Start - TRACK YOUR SESSION ID!

**IMPORTANT:** Multiple Cursor chats share the same MCP server. You MUST track your session_id to maintain separate context per chat.

## Bootstrap Context - AUTO-LOADED

When you call `session_start()`, the system automatically:

1. **Classifies intent** from the session name/project context
2. **Suggests a persona** based on the detected intent
3. **Auto-loads the persona** if confidence > 80%
4. **Shows current work** (active issues, branches)
5. **Recommends next actions** based on intent

### What Bootstrap Returns

```
## ðŸŽ¯ Bootstrap Context

**Detected Intent:** code_lookup (85% confidence)
**Auto-loading Persona:** developer (confidence: 85%)
  âœ… Switched from researcher to developer
**Active Issues:** AAP-12345, AAP-12346
**Recommended Actions:**
  - Use code_search to find relevant code
  - Check memory for similar patterns
```

### Acting on Bootstrap Context

After `session_start()` returns, **follow the recommended actions**:

| Intent | Recommended Follow-up |
|--------|----------------------|
| `code_lookup` | Call `memory_query("...")` with code-related question |
| `troubleshooting` | Call `check_known_issues()` for known fixes |
| `issue_context` | Call `jira_view_issue()` for issue details |
| `status_check` | Review the current work shown in bootstrap |
| `documentation` | Call `inscope_ask()` for documentation |

### If Persona Wasn't Auto-Loaded

If the suggested persona confidence is below 80%, the bootstrap shows:

```
**Suggested Persona:** incident (confidence: 70% - below auto-load threshold)
```

In this case, **decide based on the user's request** whether to load it:

```json
// If the task matches the suggestion, load it manually
CallMcpTool(toolName: "persona_load", arguments: {"persona": "incident"})
```

## MCP Tool Call Syntax

All session tools are called via `CallMcpTool` with the server `project-0-redhat-ai-workflow-aa_workflow`.

```json
// Start a NEW session - SAVE the returned session_id!
CallMcpTool(
  server: "project-0-redhat-ai-workflow-aa_workflow",
  toolName: "session_start",
  arguments: {}  // Returns "Session ID: abc123" - REMEMBER THIS!
)

// Resume an existing session
CallMcpTool(
  server: "project-0-redhat-ai-workflow-aa_workflow",
  toolName: "session_start",
  arguments: {"session_id": "abc123"}
)

// Start with specific agent/persona
CallMcpTool(
  server: "project-0-redhat-ai-workflow-aa_workflow",
  toolName: "session_start",
  arguments: {"agent": "devops"}  // or "developer", "incident", "release"
)

// Start with a name
CallMcpTool(
  server: "project-0-redhat-ai-workflow-aa_workflow",
  toolName: "session_start",
  arguments: {"name": "Fixing AAP-12345"}
)

// Check YOUR session (pass your session_id!)
CallMcpTool(
  server: "project-0-redhat-ai-workflow-aa_workflow",
  toolName: "session_info",
  arguments: {"session_id": "abc123"}
)
```

## Session Management Commands

```json
// List all sessions
CallMcpTool(toolName: "session_list", arguments: {})

// Switch to different session
CallMcpTool(toolName: "session_switch", arguments: {"session_id": "..."})

// Rename current session
CallMcpTool(toolName: "session_rename", arguments: {"name": "..."})
```

**Why track session_id?** Without it, `session_info()` returns whichever session was most recently active - which might be from a DIFFERENT chat window!

## Project Detection - CRITICAL

**The workspace may be `redhat-ai-workflow`, but the user might be working on a DIFFERENT project!**

When starting a conversation, Claude MUST determine the correct project and set it:

1. **Look for issue keys** (AAP-XXXXX) - these indicate work context
2. **Look for repository mentions** in user's message (automation-analytics-backend, pdf-generator)
3. **Look for file paths** that indicate which repo (/home/.../automation-analytics-backend/...)
4. **Look for GitLab paths** (automation-analytics/automation-analytics-backend)
5. **If uncertain, ASK** the user which project they're working on

Then call `session_set_project` to set the correct project:

```json
// Set project for current session
CallMcpTool(
  server: "project-0-redhat-ai-workflow-aa_workflow",
  toolName: "session_set_project",
  arguments: {"project": "automation-analytics-backend"}
)

// Or set when starting session
CallMcpTool(
  server: "project-0-redhat-ai-workflow-aa_workflow",
  toolName: "session_start",
  arguments: {"project": "automation-analytics-backend"}
)
```

**Available Projects:**
- `automation-analytics-backend` - Main backend API (AAP issues, billing, reports)
- `pdf-generator` - PDF generation service
- `app-interface` - SaaS deployment configs (APPSRE issues)
- `konflux-release-data` - Release data (KONFLUX issues)
- `redhat-ai-workflow` - This workflow system itself

**DO NOT assume `redhat-ai-workflow` is the project just because that's the workspace.**

## Dynamic Agent Loading

**Tools switch automatically when you load a new agent!**

This is a single MCP server that dynamically loads/unloads tools based on the active agent.

```
You: Load the devops agent
Claude: [calls persona_load("devops")]
        Server unloads current tools, loads k8s_basic/bonfire_basic/jira_basic/quay (~74 tools)
        Cursor receives tools/list_changed notification and refreshes
```

## Available Personas

Load a persona when the task matches their expertise:

| Persona | Tools | Best For |
|---------|-------|----------|
| **developer** | git, gitlab, jira, lint, docker, make, code_search | Coding, PRs, code review |
| **devops** | k8s, bonfire, jira, quay, docker | Ephemeral deployments, K8s ops |
| **incident** | k8s, prometheus, kibana, jira, alertmanager | Production debugging |
| **release** | konflux, quay, jira, git, appinterface | Shipping releases |

> **Note:** All personas include `jira_basic`. Use `tool_exec()` for `_extra` module tools when needed.

## Memory Usage

- **Log important actions**: `memory_session_log("action", "details")`
- **Track active work**: `memory_append("state/current_work", "active_issues", '{...}')`
- **Save learned patterns**: `memory_write("learned/patterns", content)` for reusable knowledge

## Unified Memory Query

**NEW:** Use `memory_ask` for intelligent context gathering across all sources:

### Memory Source Latency Classes

Sources are categorized by latency to keep bootstrap fast:

| Class | Sources | Latency | Used In |
|-------|---------|---------|---------|
| **Fast** | yaml, code, slack | <2s | Bootstrap, default queries |
| **Slow** | inscope, jira, gitlab, github, calendar, gmail, gdrive | >2s | On-demand only |

**Bootstrap only queries fast sources** to keep session startup under 2 seconds.

### Querying Memory

```json
// Auto-selects FAST sources only (default)
CallMcpTool(
  server: "project-0-redhat-ai-workflow-aa_workflow",
  toolName: "memory_ask",
  arguments: {"question": "What am I working on?"}
)

// Include slow sources for comprehensive results
CallMcpTool(
  toolName: "memory_ask",
  arguments: {
    "question": "How do I configure RDS?",
    "include_slow": true  // Includes inscope, jira, etc.
  }
)

// Query specific slow sources explicitly
CallMcpTool(
  toolName: "memory_ask",
  arguments: {
    "question": "What's the status of AAP-12345?",
    "sources": "jira"  // Explicit source bypasses latency filter
  }
)

// Query InScope for documentation
CallMcpTool(
  toolName: "memory_ask",
  arguments: {
    "question": "Konflux release process",
    "sources": "inscope"
  }
)
```

### When to Use Each Approach

| Situation | Approach |
|-----------|----------|
| Quick context check | Default (fast sources only) |
| Need documentation | `sources="inscope"` |
| Need issue details | `sources="jira"` |
| Need MR/pipeline info | `sources="gitlab"` |
| Comprehensive search | `include_slow=true` |
| Simple YAML read | Use `memory_read` directly |

### memory_ask Output

Returns LLM-friendly markdown with:
- **Intent classification** at the top
- **Results grouped by source**
- **Relevance scores** for weighting
- **Code blocks** preserved
- **Tip** about slow sources if not included


# Memory Operations

## Overview

Memory persists context across sessions. Use it to:
- Track active work (issues, branches, MRs)
- Store learned patterns and fixes
- Log session activity
- Query across multiple data sources

## Reading Memory

| Tool | Use Case |
|------|----------|
| `memory_read(key)` | Read a specific YAML file |
| `memory_read()` | List all available memory files |
| `memory_ask(question)` | Query across all sources (auto-routes) |
| `memory_search(query)` | Semantic search across sources |

### Examples

```python
# Read specific memory
memory_read("state/current_work")
memory_read("learned/patterns")

# Query with auto-routing
memory_ask("What am I working on?")
memory_ask("Where is the billing calculation?")
```

## Writing Memory

| Tool | Use Case |
|------|----------|
| `memory_write(key, content)` | Replace entire file |
| `memory_update(key, path, value)` | Update specific field |
| `memory_append(key, list_path, item)` | Add to a list |
| `memory_session_log(action, details)` | Log to today's session |

### Examples

```python
# Update a field
memory_update("state/current_work", "active_issues[0].status", '"In Progress"')

# Append to a list
memory_append("state/current_work", "follow_ups", '{"task": "Review MR", "priority": "high"}')

# Log an action
memory_session_log("Created MR !1234", "For AAP-12345, fixes auth bug")
```

## Learning from Errors

| Tool | Use Case |
|------|----------|
| `check_known_issues(tool, error)` | Check if we've seen this error before |
| `learn_tool_fix(tool, pattern, cause, fix)` | Save a fix for future reference |

### Examples

```python
# Check for known fixes
check_known_issues("bonfire_deploy", "manifest unknown")

# Save a fix
learn_tool_fix(
    tool_name="bonfire_deploy",
    error_pattern="manifest unknown",
    root_cause="Short SHA doesn't exist in Quay",
    fix_description="Use full 40-char SHA from git rev-parse"
)
```

## Querying External Sources

Use `memory_ask` with explicit sources for external data:

| Source | Query Example |
|--------|---------------|
| `jira` | `memory_ask("AAP-12345 status", sources="jira")` |
| `gitlab` | `memory_ask("MR pipeline status", sources="gitlab")` |
| `inscope` | `memory_ask("ClowdApp configuration", sources="inscope")` |
| `code` | `memory_ask("billing calculation", sources="code")` |
| `slack` | `memory_ask("RDS discussion", sources="slack")` |

### Latency Classes

Sources are categorized by response time:

| Class | Sources | Latency |
|-------|---------|---------|
| **Fast** | yaml, code, slack | <2s |
| **Slow** | inscope, jira, gitlab, github, calendar, gmail, gdrive | >2s |

**Default queries use fast sources only.** Add `include_slow=True` for comprehensive results:

```python
# Fast sources only (default)
memory_ask("What am I working on?")

# Include slow sources
memory_ask("How do I configure RDS?", include_slow=True)

# Query specific slow source
memory_ask("AAP-12345 details", sources="jira")
```

## Memory File Structure

```
memory/
â”œâ”€â”€ state/
â”‚   â”œâ”€â”€ current_work.yaml      # Active issues, branches, MRs
â”‚   â”œâ”€â”€ environments.yaml      # Stage/prod health status
â”‚   â””â”€â”€ projects/
â”‚       â””â”€â”€ <project>/
â”‚           â””â”€â”€ current_work.yaml  # Per-project work state
â”œâ”€â”€ learned/
â”‚   â”œâ”€â”€ patterns.yaml          # Error patterns and solutions
â”‚   â”œâ”€â”€ tool_fixes.yaml        # Tool-specific fixes
â”‚   â””â”€â”€ runbooks.yaml          # Procedures that worked
â””â”€â”€ sessions/
    â””â”€â”€ YYYY-MM-DD.yaml        # Daily session logs
```

## Common Patterns

### Starting Work on an Issue

```python
memory_append("state/current_work", "active_issues", '''
  key: AAP-12345
  summary: Fix authentication bug
  status: In Progress
  branch: aap-12345-fix-auth
''')
```

### Recording a Learning

```python
learn_tool_fix(
    "kubectl_logs",
    "container not found",
    "Pod has multiple containers",
    "Specify container with -c flag"
)
```

### End of Day Summary

```python
memory_session_log("End of day", '''
  Completed:
  - Fixed AAP-12345 (MR !1234)
  - Reviewed AAP-12346
  Tomorrow:
  - Deploy to stage
  - Address review comments
''')
```


# Git Safety Rules

## â›” CRITICAL: Never Discard Work Without Permission

**NEVER run `git checkout` on files without explicit user permission!**

This has caused catastrophic loss of uncommitted work. Before ANY git operation that could discard changes:

1. **ASK the user first** - "Can I revert file X? This will discard uncommitted changes."
2. **Check `git status`** - See what's modified
3. **Check `git diff`** - See what would be lost
4. **Consider `git stash`** - Preserve changes before destructive operations

## Destructive Commands Requiring Permission

These commands require explicit user permission:

| Command | Effect |
|---------|--------|
| `git checkout -- <file>` | Discards changes to file |
| `git reset --hard` | Discards ALL changes |
| `git clean -fd` | Deletes untracked files |
| `git stash drop` | Deletes stashed changes |

## Safe Workflow

```bash
# ALWAYS check first
git status
git diff

# If you need to discard changes, ASK FIRST
# "Can I revert changes to src/app.py? This will discard uncommitted work."

# If user agrees, prefer stash over discard
git stash push -m "Before reverting src/app.py"
```

## Commit Conventions

- **Commit messages**: Use `git_commit` tool - format from `config.json`: `{issue_key} - {type}({scope}): {description}`
- **Branch names**: `aap-xxxxx-short-description`
- **Always link Jira issues** in MR descriptions
- **Check pipeline status** after pushing


# Ephemeral Deployment Rules

## âš ï¸ CRITICAL: Kubeconfig Rules

**NEVER copy kubeconfig files!** Each environment has its own config:

| File | Environment |
|------|-------------|
| `~/.kube/config.s` | Stage |
| `~/.kube/config.p` | Production |
| `~/.kube/config.e` | Ephemeral |

```bash
# WRONG - NEVER DO THIS:
cp ~/.kube/config.e ~/.kube/config

# RIGHT - use --kubeconfig flag:
kubectl --kubeconfig=~/.kube/config.e get pods -n ephemeral-xxx
oc --kubeconfig=~/.kube/config.e get pods -n ephemeral-xxx

# RIGHT - use KUBECONFIG env for bonfire:
KUBECONFIG=~/.kube/config.e bonfire namespace list --mine
```

## Deployment Rules

1. **Use the skill**: `skill_run("test_mr_ephemeral", '{"mr_id": 1459}')`
2. **Image tags must be FULL 40-char git SHA** - short SHAs (8 chars) don't exist in Quay
3. **Only release YOUR namespaces**: `bonfire namespace list --mine`
4. **ITS deploy pattern requires sha256 digest**, not git SHA for IMAGE_TAG

## ClowdApp Deployment

When deploying from **automation-analytics-backend** repo:
- **Ask which ClowdApp** to deploy: main or billing
- **Default to main** if user doesn't specify

| ClowdApp | Name |
|----------|------|
| Main (default) | `tower-analytics-clowdapp` |
| Billing | `tower-analytics-billing-clowdapp` |

```python
# Main (default):
skill_run("test_mr_ephemeral", '{"mr_id": 1459, "billing": false}')

# Billing:
skill_run("test_mr_ephemeral", '{"mr_id": 1459, "billing": true}')
```

## Namespace Safety

```bash
# Check YOUR namespaces only:
KUBECONFIG=~/.kube/config.e bonfire namespace list --mine

# NEVER release namespaces you don't own
```

## Project Context

Key namespaces for Automation Analytics:
- **Konflux**: `aap-aa-tenant`
- **Stage**: `tower-analytics-stage`
- **Production**: `tower-analytics-prod`


# Auto-Debug: Self-Healing Tools

When an MCP tool fails (returns âŒ), you can fix the tool itself.

## Workflow

1. **Tool fails** â†’ Look for the hint: `ðŸ’¡ To auto-fix: debug_tool('tool_name')`
2. **Call debug_tool** â†’ `debug_tool('bonfire_namespace_release', 'error message')`
3. **Analyze the source** â†’ Compare error to code, identify the bug
4. **Propose a fix** â†’ Show exact `search_replace` edit
5. **Ask user to confirm** â†’ "Found bug: missing --force flag. Apply fix?"
6. **Apply and commit** â†’ `git commit -m "fix(tool_name): description"`

## Example

```
Tool output: âŒ Failed to release namespace
             ðŸ’¡ To auto-fix: `debug_tool('bonfire_namespace_release')`

You: [call debug_tool('bonfire_namespace_release', 'Output is not a TTY. Aborting.')]

Claude: "I found the bug. The bonfire CLI prompts for confirmation but we're
         not passing --force. Here's the fix:

         File: tool_modules/aa-bonfire/src/tools.py
         - args = ['namespace', 'release', namespace]
         + args = ['namespace', 'release', namespace, '--force']

         Apply this fix?"

User: "yes"

Claude: [applies fix, commits, retries operation]
```

## Common Fixable Bugs

| Error Pattern | Likely Cause |
|---------------|--------------|
| "Output is not a TTY" | Missing --force/--yes flag |
| "Unknown flag: --state" | CLI syntax changed |
| "Unauthorized" | Auth not passed correctly |
| "manifest unknown" | Wrong image tag format |

## Check Known Issues First

Before debugging, check if we've seen this error before:

```python
check_known_issues(tool_name="bonfire_deploy", error_text="manifest unknown")
```

## Save Fixes for Future

After fixing a tool, save the pattern:

```python
learn_tool_fix(
    tool_name="bonfire_deploy",
    error_pattern="manifest unknown",
    root_cause="Short SHA doesn't exist in Quay",
    fix_description="Use full 40-char SHA"
)
```


# Work Completion: Update Jira After Work Done

## The Rule

**After completing work on a Jira issue, ALWAYS update the issue status and add a comment summarizing what was done.**

This keeps Jira in sync with reality and provides audit trail for the work.

## When to Update Jira

Update Jira after ANY of these actions:

| Action Completed | Jira Update |
|------------------|-------------|
| Created MR/PR | Transition to "In Review", add comment with MR link |
| MR merged | Transition to "Done" or "Closed", add comment |
| Code committed | Add comment summarizing changes |
| Bug fixed | Add comment with fix details |
| Investigation complete | Add comment with findings |
| Work blocked | Transition to "Blocked", add comment explaining blocker |
| Work paused | Add comment explaining why |

## How to Update Jira

### 1. Ensure Jira Tools Are Available

All personas include `jira_core` with essential tools. If you need additional Jira tools, load the developer persona:

```json
CallMcpTool(
  server: "project-0-redhat-ai-workflow-aa_workflow",
  toolName: "persona_load",
  arguments: {"persona": "developer"}
)
```

### 2. Transition the Issue Status

Use `jira_transition` to change the status:

```json
CallMcpTool(
  server: "project-0-redhat-ai-workflow-aa_workflow",
  toolName: "jira_transition",
  arguments: {
    "issue_key": "AAP-12345",
    "status": "In Review"
  }
)
```

Common status transitions:
- **Starting work**: "Open" â†’ "In Progress"
- **MR created**: "In Progress" â†’ "In Review"
- **MR merged**: "In Review" â†’ "Done"
- **Work blocked**: Any â†’ "Blocked"

### 3. Add a Comment

Use `jira_add_comment` to document what was done:

```json
CallMcpTool(
  server: "project-0-redhat-ai-workflow-aa_workflow",
  toolName: "jira_add_comment",
  arguments: {
    "issue_key": "AAP-12345",
    "comment": "MR created: https://gitlab.com/.../merge_requests/1234\n\nChanges:\n- Fixed the authentication bug\n- Added unit tests"
  }
)
```

## Comment Templates

### MR Created
```
MR created: {mr_url}

Changes:
- {change_1}
- {change_2}

Ready for review.
```

### MR Merged
```
MR merged: {mr_url}

Deployed to: {environment}
Commit: {sha}
```

### Investigation Complete
```
Investigation findings:

Root cause: {cause}
Recommendation: {recommendation}
```

### Work Blocked
```
Blocked by: {blocker_issue_key or description}

Reason: {explanation}
Next steps: {what_needs_to_happen}
```

## Workflow Integration

### After `create_mr` Skill
The `create_mr` skill should already handle this, but if doing manual MR creation:

1. Create the MR
2. Call `jira_transition(issue_key, "In Review")`
3. Call `jira_add_comment(issue_key, "MR created: {url}")`

### After Manual Code Work
When completing code changes outside of skills:

1. Commit the changes
2. Push to remote
3. Call `jira_add_comment(issue_key, "Committed: {summary of changes}")`
4. If work is complete, call `jira_transition(issue_key, "In Review")` or "Done"

### After `close_issue` Skill
The `close_issue` skill handles this automatically.

## Don't Forget

- **Always include the issue key** from the user's request or session context
- **Be specific in comments** - include MR links, commit SHAs, file names
- **Match the project's workflow** - AAP uses: Open â†’ In Progress â†’ In Review â†’ Done
- **Check current status first** if unsure - use `jira_view_issue(issue_key)`

## Example Workflow

```
User: "fix the bug in AAP-12345 and create an MR"

Claude:
1. [Read the issue to understand the bug]
2. [Make the code fix]
3. [Create MR]
4. [Update Jira]:
   - jira_transition("AAP-12345", "In Review")
   - jira_add_comment("AAP-12345", "MR created: https://...")
5. [Report to user]
```


# CRITICAL: Use MCP Tools Instead of Raw CLI

## The Rule

**NEVER run a CLI command via the Shell tool when an MCP tool exists for it.**

Blocked commands are **automatically rejected** by hooks across all AI tools:
- **Cursor**: `beforeShellExecution` hook (`.cursor/hooks.json`)
- **Claude Code**: `PreToolUse` hook (`.claude/settings.json`)
- **Gemini CLI**: `BeforeTool` hook (`.gemini/settings.json`)
- **GitHub Copilot**: `preToolUse` hook (`.github/hooks/hooks.json`)
- **OpenCode**: bash permission denials (`opencode.json`)
- **Codex**: approval policy + AGENTS.md rules (`.codex/config.toml`)

All hook-based tools share a single script: `.cursor/hooks/block-cli.sh`. The blocklist is defined in `config.json` -> `cli_to_mcp`.

MCP tools are superior because they:
- Handle **authentication** automatically (tokens, kubeconfig, API keys)
- Provide **error recovery** and auto-healing
- Log to **memory** for session context
- Are **auditable** and reproducible
- Return **structured, formatted** output

## Decision Tree

Before running any command:

```
1. Is there an MCP tool for this? â†’ Check the table below
   â”œâ”€ YES â†’ Is the right persona loaded?
   â”‚        â”œâ”€ YES â†’ Call the MCP tool directly
   â”‚        â””â”€ NO  â†’ Load persona first: persona_load("...")
   â””â”€ NO  â†’ Is it in the allowed list? â†’ Use shell()
            â””â”€ Unknown â†’ shell() will let it through
```

## CLI-to-MCP Tool Mapping

### Network / HTTP

| CLI Command | MCP Module | MCP Tools | Load Persona |
|-------------|-----------|-----------|--------------|
| `curl` | `aa_curl` | `curl_get()`, `curl_post()`, `curl_put()`, `curl_delete()`, `curl_patch()` | `developer` |
| `wget` | `aa_curl` | `curl_download()` | `developer` |

### Git / Version Control

| CLI Command | MCP Module | MCP Tools | Load Persona |
|-------------|-----------|-----------|--------------|
| `git` | `aa_git` | `git_status()`, `git_commit()`, `git_push()`, `git_diff()`, `git_log()` | `developer` |

### Kubernetes / OpenShift

| CLI Command | MCP Module | MCP Tools | Load Persona |
|-------------|-----------|-----------|--------------|
| `kubectl` | `aa_k8s` | `kubectl_get_pods()`, `kubectl_logs()`, `kubectl_get_deployments()`, `kubectl_describe_pod()` | `devops` |
| `oc` | `aa_k8s` | `kubectl_get_pods()`, `kubectl_logs()`, `kubectl_exec()` | `devops` |
| `bonfire` | `aa_bonfire` | `bonfire_deploy()`, `bonfire_namespace_list()`, `bonfire_namespace_reserve()` | `devops` |
| `helm` | `aa_k8s` | `kubectl_get()` | `devops` |

### GitHub / GitLab

| CLI Command | MCP Module | MCP Tools | Load Persona |
|-------------|-----------|-----------|--------------|
| `gh` | `aa_github` | `gh_pr_list()`, `gh_pr_view()`, `gh_run_list()`, `gh_run_view()`, `gh_issue_list()` | `github` |
| `glab` | `aa_gitlab` | `gitlab_mr_view()`, `gitlab_list_mrs()`, `gitlab_ci_status()`, `gitlab_ci_view()` | `developer` |

### Containers

| CLI Command | MCP Module | MCP Tools | Load Persona |
|-------------|-----------|-----------|--------------|
| `docker` | `aa_docker` | `docker_ps()`, `docker_compose_up()`, `docker_compose_down()`, `docker_logs()`, `docker_exec()` | `devops` |
| `docker-compose` | `aa_docker` | `docker_compose_up()`, `docker_compose_down()`, `docker_compose_status()` | `devops` |
| `podman` | `aa_podman` | `podman_ps()`, `podman_run()`, `podman_logs()`, `podman_exec()` | `devops` |

### System Administration

| CLI Command | MCP Module | MCP Tools | Load Persona |
|-------------|-----------|-----------|--------------|
| `ssh` / `sshpass` | `aa_ssh` | `ssh_command()`, `ssh_test()` | `security` |
| `systemctl` | `aa_systemd` | `systemctl_status()`, `systemctl_restart()`, `systemctl_start()`, `systemctl_stop()` | `infra` |
| `journalctl` | `aa_systemd` | `journalctl_unit()`, `journalctl_logs()`, `journalctl_boot()` | `infra` |
| `virsh` | `aa_libvirt` | `virsh_list()`, `virsh_start()`, `virsh_shutdown()`, `virsh_destroy()` | `infra` |
| `virt-install` | `aa_libvirt` | `virt_install()` | `infra` |

### Linting / Testing

| CLI Command | MCP Module | MCP Tools | Load Persona |
|-------------|-----------|-----------|--------------|
| `flake8` / `mypy` / `black` / `isort` / `ruff` | `aa_lint` | `lint_python()` | `developer` |
| `pytest` | `aa_lint` | `test_run()`, `test_coverage()` | `developer` |
| `make` | `aa_make` | `make_target()` | `code` |

### Security

| CLI Command | MCP Module | MCP Tools | Load Persona |
|-------------|-----------|-----------|--------------|
| `openssl` | `aa_openssl` | `openssl_s_client()`, `openssl_x509_info()`, `openssl_x509_verify()` | `security` |
| `nmap` | `aa_nmap` | `nmap_scan()`, `nmap_quick_scan()`, `nmap_vuln_scan()` | `security` |

### Databases

| CLI Command | MCP Module | MCP Tools | Load Persona |
|-------------|-----------|-----------|--------------|
| `psql` | `aa_postgres` | `psql_query()`, `psql_tables()`, `psql_describe()` | `database` |
| `mysql` | `aa_mysql` | `mysql_query()`, `mysql_tables()`, `mysql_describe()` | `database` |
| `sqlite3` | `aa_sqlite` | `sqlite_query()`, `sqlite_tables()`, `sqlite_schema()` | `database` |

### Cloud / Infrastructure

| CLI Command | MCP Module | MCP Tools | Load Persona |
|-------------|-----------|-----------|--------------|
| `aws` | `aa_aws` | `aws_s3_ls()`, `aws_s3_cp()`, `aws_ec2_describe_instances()` | `infra` |
| `gcloud` | `aa_gcloud` | `gcloud_compute_instances_list()`, `gcloud_storage_ls()`, `gcloud_config_list()` | `infra` |
| `ansible` / `ansible-playbook` | `aa_ansible` | `ansible_playbook_run()`, `ansible_ping()`, `ansible_command()` | `infra` |

### CI/CD / Releases

| CLI Command | MCP Module | MCP Tools | Load Persona |
|-------------|-----------|-----------|--------------|
| `tkn` | `aa_konflux` | `tkn_pipelinerun_list()`, `tkn_pipelinerun_logs()`, `tkn_pipelinerun_describe()` | `release` |
| `skopeo` | `aa_quay` | `skopeo_get_digest()`, `quay_list_tags()` | `release` |

### Project Management

| CLI Command | MCP Module | MCP Tools | Load Persona |
|-------------|-----------|-----------|--------------|
| `rh-issue` | `aa_jira` | `jira_view_issue()`, `jira_search()`, `jira_my_issues()` | `developer` |

## Allowed Commands (OK to use via shell)

These commands are explicitly allowed through `shell()` because they are basic utilities without MCP equivalents:

- **File operations:** `ls`, `cat`, `head`, `tail`, `grep`, `rg`, `find`, `wc`, `file`, `stat`
- **Output:** `echo`, `printf`, `date`, `whoami`, `hostname`, `uname`, `id`
- **File management:** `cd`, `pwd`, `mkdir`, `cp`, `mv`, `rm`, `touch`, `chmod`, `chown`, `ln`
- **Language runtimes:** `python`, `python3`, `node`, `npm`, `pip`, `pipenv`, `uv`
- **Data processing:** `jq`, `yq`, `sed`, `awk`, `sort`, `uniq`, `tr`, `cut`, `paste`, `column`
- **Process control:** `sleep`, `timeout`, `kill`, `pkill`, `ps`, `top`, `df`, `du`, `free`
- **Archives:** `tar`, `gzip`, `gunzip`, `zip`, `unzip`
- **Shell builtins:** `env`, `export`, `source`, `which`, `type`, `command`, `test`, `set`

## Quick Persona Reference

| Domain | Persona | Key Modules |
|--------|---------|-------------|
| Coding, PRs, linting | `developer` | git, gitlab, jira, lint, curl |
| Kubernetes, containers, ephemeral | `devops` | k8s, bonfire, docker, podman, quay |
| Alerts, incidents, logs | `incident` | k8s, prometheus, kibana, alertmanager |
| Releases, pipelines | `release` | konflux, quay, git, appinterface |
| GitHub workflows | `github` | github, git, jira |
| Security scanning | `security` | nmap, openssl, ssh |
| Databases | `database` | postgres, mysql, sqlite, ssh |
| Infrastructure, cloud | `infra` | ansible, aws, gcloud, systemd, ssh, libvirt |
